{# app/Resources/views/home.html.twig #}
{# app/Resources/views/banners.html.twig #}
{% extends 'base.html.twig' %}
    {% block loginButton %}
        
    {% endblock %}

{% block pagebody %}
<section id="about" class="page hero-banner">
    <div class="inner"></div>
    <div class="container-fluid">
        <div class="row">
            {% block hero %}
            <div class="page-header">
                <h1 class="page-title">About Microservices</h1>
                <a class="learn-more-btn" href="#">Learn more at nignx.com</a>
            </div>
            <div class="page-gradient"></div>
            {% endblock %}
            {% block article %}
            <div class="page-content">
                <h2>Introduction</h2>

                <p>NGINX has been involved in the microservices movement from the very beginning. The lightweight, high-performance, and flexible nature of NGINX is a great fit for microservices.</p>
                <p>The <a href="https://hub.docker.com/_/nginx/">NGINX Docker image</a> is the number one downloaded application image on Docker Hub, and most microservices platforms you find on the Web today include a demo that deploys NGINX in some form and connects to the welcome page.</p>
                <p>Because we believe moving to microservices is crucial to the success of our customers, we at NGINX have launched a dedicated program to develop features and practices in support of this seismic shift in web application development and delivery. We also recognize that there are many different approaches to implementing microservices, many of them novel and specific to the needs of individual development teams. We think there is a need for models to make it easier for companies to develop and deliver their own microservices-based applications.</p>
                <p>With all this in mind, we here in NGINX Professional Services are developing the NGINX Microservices Reference Architecture (MRA) – a set of models that you can use to create your own microservices applications.</p>
                <p>The MRA is made up of two components: a detailed description of each of the three Models, plus downloadable code that implements our example photo-sharing program, Ingenious. The only difference among the three Models is the configuration code that’s used to configure NGINX Plus for each of them. </p>
                <p>Our goal in building this Reference Architecture is threefold:</p>
                <ul>
                    <li>To provide customers and the industry with ready-to-use blueprints for building microservices-based systems, speeding&nbsp;– and improving&nbsp;– development.</li>
                    <li>To create a platform for testing new features in NGINX and NGINX&nbsp;Plus, whether developed internally or externally and distributed in the  product core or as <a href="https://www.nginx.com/blog/tag/dynamic-modules/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">dynamic modules</a>. </li>
                    <li>To help us understand partner systems and components so we can gain a holistic perspective on the microservices ecosystem.</li>
                </ul>
                <p>The Microservices Reference Architecture is also an important part of <a href="https://www.nginx.com/services/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">professional services offerings</a> for NGINX customers. In the MRA, we use features common to both the <a target="_blank" href="http://www.nginx.org/en/">open source NGINX software</a> and <a href="https://www.nginx.com/products/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">NGINX&nbsp;Plus</a> where possible, and NGINX&nbsp;Plus‑specific features where needed. NGINX&nbsp;Plus dependencies are stronger in the more complex models, as described below. We anticipate that many users of the MRA will benefit from access to NGINX professional services and to technical support, which comes with an NGINX&nbsp;Plus subscription. </p>

                <hr/>

                <h2>An Overview of the Microservices Reference Architecture</h2>

                <p>We are building the Reference Architecture to be compliant with the principles of the <a href="https://www.nginx.com/blog/microservices-reference-architecture-nginx-twelve-factor-app/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">Twelve‑Factor&nbsp;App</a>. The services are designed to be lightweight, ephemeral, and stateless. </p>
                <p>The MRA uses industry standard components like Docker containers, a wide range of languages&nbsp;– Java, PHP, Python, NodeJS/JavaScript, and Ruby&nbsp;– and NGINX-based networking. </p>
                <p>One of the biggest changes in application design and architecture when moving to microservices is using the network to communicate between functional components of the application. In monolithic apps, application components communicate in memory. In a microservices app, that communication happens over the network, so network design and implementation become critically important. </p>
                <p>To reflect this, the MRA has been implemented using three different networking models, all of which use NGINX or NGINX&nbsp;Plus. They range from relatively simple to feature-rich and more complex:  </p>
                <ul>
                    <li><a href="#proxy"><strong>Proxy&nbsp;Model</strong></a>&nbsp;– A simple networking model suitable for implementing NGINX&nbsp;Plus as a controller or <a href="https://www.nginx.com/blog/building-microservices-using-an-api-gateway/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">API gateway</a> for a microservices application. This model is built on top of Docker Cloud.</li>
                    <li><a href="#router-mesh"><strong>Router&nbsp;Mesh&nbsp;Model</strong></a>&nbsp;– A more robust approach to networking, with a load balancer on each host and management of the connections between systems. This model is similar to the architecture of <a target="_blank" href="https://www.ctl.io/developers/blog/post/deis-1-0-released-popular-docker-paas-becoming-more-robust/">Deis 1.0</a>.</li>
                    <li><a href="#fabric"><strong>Fabric&nbsp;Model</strong></a>&nbsp;– The crown jewel of the MRA, the Fabric&nbsp;Model features NGINX&nbsp;Plus in each container, acting as a forward and reverse proxy. It works well for high-load systems and supports SSL/TLS at all levels, with NGINX&nbsp;Plus providing reduced latency, persistent SSL/TLS connections, service discovery, and the circuit breaker pattern across all microservices.</li>
                </ul>
                <p>Our intention is that you use these models as a starting point for your own microservices implementations, and we welcome feedback from you as to how to improve the MRA. </p>
                <p>A brief description of each model follows; we suggest you read all the descriptions to start getting an idea of how you might best use one or more of the models. </p>

                <hr/>

                <h2 id="proxy">The Proxy Model in Brief</h2>

                <p>The Proxy&nbsp;Model is a relatively simple networking model. It’s an excellent starting point for an initial microservices application, or as a target model in <a href="https://www.nginx.com/blog/refactoring-a-monolith-into-microservices/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">converting</a> a moderately complex monolithic legacy app. </p>
                <p>In the Proxy&nbsp;Model, NGINX or NGINX&nbsp;Plus acts as an ingress controller, routing requests to microservices. NGINX&nbsp;Plus can use dynamic DNS for <a href="https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">service discovery</a> as new services are created. The Proxy&nbsp;Model is also suitable for use as a template when using NGINX as an <a href="https://www.nginx.com/blog/building-microservices-using-an-api-gateway/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">API gateway</a>. </p>
                <p align="center"><img src="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture.png" alt="In the Proxy Model of the Microservices Reference Architecture from NGINX, NGINX Plus acts as a reverse proxy server and ingress controller for the microservice instances of an application" width="800" height="496" class="aligncenter size-full wp-image-47188" style="border:2px solid #666666; padding:2px; margin:2px;" srcset="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture.png 800w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-300x186.png 300w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-768x476.png 768w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-150x93.png 150w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-640x397.png 640w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-380x235.png 380w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Proxy-Model_NGINX-Microservices-Reference-Architecture-320x198.png 320w" sizes="(max-width: 800px) 100vw, 800px"></p>
                <p>If interservice communication is needed&nbsp;– and it is by most applications of any level of complexity&nbsp;– the service registry provides the  mechanism within the cluster. (See this blog post for a detailed list of <a href="https://www.nginx.com/blog/building-microservices-inter-process-communication/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">interservice communications mechanisms</a>.) Docker Cloud uses this approach by default; to connect to another service, a service queries the DNS and gets an IP address to send a request to. </p>
                <p>Generally, the Proxy&nbsp;Model is workable for simple to moderately complex applications. It’s not the most efficient approach/Model for load balancing, especially at scale; use one of the models described below if you have heavy load balancing requirements. (“Scale” can refer to a large number of microservices as well as high traffic volumes.) </p>
                <p><em>Editor&nbsp;– For an in‑depth exploration of this model, see <a href="https://www.nginx.com/blog/microservices-reference-architecture-nginx-proxy-model/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">MRA, Part&nbsp;2&nbsp;– The Proxy&nbsp;Model</a>.</em></p>

                <hr/>

                <h2 id="router-mesh">Stepping Up to the Router Mesh Model</h2>

                <p>The Router&nbsp;Mesh&nbsp;Model is moderately complex and is a good match for robust new application designs, and also for converting more complex, monolithic legacy apps that don’t need the capabilities of the Fabric&nbsp;Model. </p>
                <p>The Router&nbsp;Mesh&nbsp;Model takes a more robust approach to networking than the Proxy&nbsp;Model, by running a load balancer on each host and actively managing connections between microservices. The key benefit of the Router&nbsp;Mesh&nbsp;Model is more efficient and robust load balancing between services. If you use NGINX&nbsp;Plus, you can implement <a href="https://www.nginx.com/products/application-health-checks/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">active health checks</a> to monitor the individual service instances and throttle traffic gracefully when they are taken down. </p>
                <p align="center"><img src="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture.png" alt="In the Router Mesh Model of the Microservices Reference Architecture from NGINX, NGINX Plus runs on each server to load balance the microservices running there, and also on frontend servers to reverse proxy and load balance traffic to the application servers" width="800" height="496" class="aligncenter size-full wp-image-47187" style="border:2px solid #666666; padding:2px; margin:2px;" srcset="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture.png 800w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-300x186.png 300w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-768x476.png 768w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-150x93.png 150w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-640x397.png 640w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-380x235.png 380w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Router-Mesh-Model_NGINX-Microservices-Reference-Architecture-320x198.png 320w" sizes="(max-width: 800px) 100vw, 800px"></p>
                <p><a target="_blank" href="https://github.com/deis/workflow">Deis Workflow</a> uses an approach similar to the Router&nbsp;Mesh&nbsp;Model to route traffic between services, with instances of NGINX running in a container on each host. As new app instances are spun up, a process extracts service information from the <a href="https://www.nginx.com/blog/service-discovery-nginx-plus-etcd/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">etcd</a> service registry and loads it into NGINX. NGINX&nbsp;Plus can work in this mode as well, using various locations and their associated upstreams. </p>
                <p><em>Editor&nbsp;– For an in‑depth exploration of this model, see <a href="https://www.nginx.com/blog/microservices-reference-architecture-nginx-router-mesh-model/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">MRA, Part&nbsp;3&nbsp;– The Router&nbsp;Mesh&nbsp;Model</a>.</em></p>

                <hr/>

                <h2 id="fabric">And Finally&nbsp;– The Fabric Model, with Optional SSL/TLS</h2>

                <p>We here at NGINX are most excited about the Fabric&nbsp;Model. It brings some of the most exciting promises of microservices to life, including high performance, flexibility in load balancing, and ubiquitous SSL/TLS down to the level of individual microservices. The Fabric&nbsp;Model is suitable for secure applications and scalable to very large applications. </p>
                <p>In the Fabric&nbsp;Model, NGINX&nbsp;Plus is deployed within each container and becomes the forward and reverse proxy for all HTTP traffic going in and out of the containers. The applications talk to a localhost location for all service connections and rely on NGINX&nbsp;Plus to do service discovery, load balancing, and health checking. </p>
                <p align="center"><img src="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture.png" alt="In the Fabric Model of the Microservices Reference Architecture from NGINX, NGINX Plus is deployed within each container and becomes the forward and reverse proxy for all HTTP traffic going in and out of the containers" width="800" height="496" class="aligncenter size-full wp-image-47189" style="border:2px solid #666666; padding:2px; margin:2px;" srcset="https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture.png 800w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-300x186.png 300w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-768x476.png 768w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-150x93.png 150w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-640x397.png 640w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-380x235.png 380w, https://cdn.wp.nginx.com/wp-content/uploads/2016/11/Fabric-Model_NGINX-Microservices-Reference-Architecture-320x198.png 320w" sizes="(max-width: 800px) 100vw, 800px"></p>
                <p>In our configuration, NGINX&nbsp;Plus queries <a href="https://www.nginx.com/blog/service-discovery-nginx-plus-zookeeper/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">ZooKeeper</a> for all instances of the services that the app needs to connect to. With the DNS frequency setting, <code>valid</code>, set to 1&nbsp;second, for example, NGINX&nbsp;Plus scans ZooKeeper for instance changes every second, and routes traffic appropriately. </p>
                <p>Because of the powerful HTTP processing in NGINX&nbsp;Plus, we can use keepalives to maintain stateful connections to microservices, reducing latency and improving performance. This is an especially valuable feature when using SSL/TLS to secure traffic between the microservices. </p>
                <p>Finally, we use NGINX&nbsp;Plus’ active health checks to manage traffic to healthy instances and, essentially, build in the <a target="_blank" href="http://martinfowler.com/bliki/CircuitBreaker.html">circuit breaker pattern</a> for free. </p>
                <p><em>Editor&nbsp;– For an in‑depth exploration of this model, see <a href="https://www.nginx.com/blog/microservices-reference-architecture-nginx-fabric-model/?utm_source=introducing-the-nginx-microservices-reference-architecture&amp;utm_medium=blog&amp;utm_campaign=Microservices">MRA, Part&nbsp;4&nbsp;– The Fabric&nbsp;Model</a>.</em></p>

                <hr/>

                <h2>An Ingenious Demo App for the MRA</h2>

                <p>The MRA includes a sample application as a demo: the Ingenious photo-sharing app. Ingenious is implemented in each of the three models&nbsp;– Proxy, Router&nbsp;Mesh, and Fabric. </p>
                <p>Ingenious is a simplified version of a photo storage and sharing application, a la Flickr or Shutterfly. We chose a photo-sharing application for a few reasons:</p>
                <ul>
                    <li>It is easy for both users and developers to grasp what it does.</li>
                    <li>There are multiple data dimensions to manage.</li>
                    <li>It is easy to incorporate beautiful design in the app.</li>
                    <li>It provides asymmetric computing requirements&nbsp;– a mix of high-intensity and low-intensity processing&nbsp;– which enables realistic testing of failover, scaling, and monitoring features across different kinds of functionality.</li>
                </ul>

            </div>
            {% endblock %}
        </div>
    </div> <!--./end container-->
</section><!-- ./ end post content-->
{% endblock %}
